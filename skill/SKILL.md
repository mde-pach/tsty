---
name: tsty
description: "Autonomous E2E testing framework for iterative visual QA and user flow validation. Creates, executes, and autonomously fixes test flows until passing. Use when asked to: (1) test/verify/validate UI, frontend, web app, or pages; (2) check layout, visual bugs, styling, or design; (3) test accessibility/WCAG/a11y; (4) run E2E/integration/user flow/journey/scenario tests; (5) test form submissions, interactions, or user actions; (6) verify API integrations from frontend; (7) regression test after changes; (8) debug/troubleshoot UI issues; (9) analyze screenshots, console logs, or test reports; (10) automate browser testing with Playwright. Works with ANY tech stack (React, Vue, Next.js, vanilla JS, etc.). CRITICAL: Autonomously iterates (run â†’ analyze â†’ fix code â†’ re-run) until tests pass. Uses micro-iteration (test ONE step at a time) and fail-fast mode for fastest debugging."
---

# Tsty - Iterative Visual QA Testing Skill

**Iterative QA testing framework** that autonomously creates flows, runs tests, analyzes results (screenshots/logs/reports), fixes issues, and re-runs until tests pass.

## âš ï¸ CRITICAL PRINCIPLES (Read These First)

**These are the MOST COMMON failure modes from real testing sessions. Violating these wastes 60+ minutes per session.**

### 1. ğŸ‘¤ Test Like a Human User (NOT test automation engineer)

**ALWAYS ask: "How would a human do this?" Then do exactly that.**

```json
âœ… CORRECT (user-like):
{ "type": "click", "selector": "text=Save" }
{ "type": "click", "selector": "text=Focus" }
{ "type": "fill", "selector": "placeholder=Email", "value": "test@test.com" }

âŒ WRONG (engineer-like):
{ "type": "dragAndDrop", ... }  // Before trying click!
{ "type": "evaluate", "pageFunction": "..." }  // Before trying UI interaction!
{ "selector": "div:has-text('Focus'):has-text('Focus an element')" }  // Over-complex!
```

**Interaction hierarchy (try in order):**
1. Simple click (`text=`, `placeholder=`, `button:has-text()`)
2. Fill/type for inputs
3. Keyboard shortcuts (if user would use them)
4. Drag-and-drop (ONLY if click fails first)
5. JavaScript evaluate (LAST RESORT - usually means bug!)

**â†’ Details: [USER-FIRST-TESTING.md](references/USER-FIRST-TESTING.md)**

### 2. ğŸ”§ Fix Bugs, Don't Assume Framework Limitations

**Test passed âœ“ + Screenshot unchanged âœ— = FALSE SUCCESS = App bug**

```
DEFAULT ASSUMPTION (from real data):
â”œâ”€ 70% Application bugs (missing onClick, broken logic)
â”œâ”€ 25% Wrong test selectors
â”œâ”€ 4% Timing issues
â””â”€ 1% Framework limitations

When feature doesn't work:
1. Try simple user interaction (text= + click)
2. Still broken? Read the component code
3. Find the bug (missing handler, wrong logic)
4. Fix the application code
5. Re-run test
6. Verify fix worked
```

**NEVER conclude "framework limitation" without:**
- âœ… Trying simple `text=` selector + click
- âœ… Reading component code
- âœ… Verifying event handlers exist
- âœ… Testing 3+ different approaches

**â†’ Details: [BUG-FIXING-WORKFLOW.md](references/BUG-FIXING-WORKFLOW.md)**

### 3. ğŸ”„ Autonomous Iteration (Don't Just Report)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YOU ARE THE TESTER AND THE FIXER        â”‚
â”‚ Don't report failures - FIX them        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Loop: CREATE â†’ RUN â†’ ANALYZE â†’ FIX â†’ RE-RUN
Exit when: exit code 0 AND screenshots correct
```

**What to fix:**
- Console errors â†’ Fix **application JavaScript**
- Selector timeouts â†’ Fix **test selectors**
- Visual bugs â†’ Fix **application CSS/layout**
- Missing features â†’ **Add them to the app**

**â†’ Details: [ITERATIVE-WORKFLOW.md](references/ITERATIVE-WORKFLOW.md)**

### 4. ğŸ§ª Micro-Iteration (Test ONE Action at a Time)

```
âŒ NEVER:
1. Create 9 actions
2. Create 9-step flow
3. Run â†’ All fail
4. Waste 30+ min debugging

âœ… ALWAYS:
1. Create 1 action
2. Test in 2-step flow (15s)
3. Fix if fails
4. Create next action (only after #1 works)
5. Repeat
```

**The Iron Rule:** Never have more than 1 untested action.

**â†’ Details: [ITERATIVE-WORKFLOW.md](references/ITERATIVE-WORKFLOW.md)**

---

## ğŸš¨ OUTCOME VERIFICATION IS MANDATORY

**âš ï¸ CRITICAL: "Test passed" â‰  "Feature works"**

```
Exit code 0 means: Playwright didn't crash
Feature works means: A human user can accomplish their goal

ALWAYS VERIFY BOTH
```

### After EVERY Test Run (MANDATORY)

**âœ… Verification Checklist:**

â–¡ **Screenshot shows expected UI change?**
  - Button clicked â†’ Something appeared/changed?
  - Form filled â†’ Data visible in UI?
  - Item added â†’ Count increased?

â–¡ **Data created/updated (check files)?**
  - File exists AND has correct content?
  - Database updated with right values?
  - API called with expected payload?

â–¡ **Would a real user be satisfied?**
  - Feature actually usable?
  - No broken UI or partial states?
  - Workflow completes end-to-end?

**If ANY checkbox is unchecked â†’ BUG in application. Investigate immediately.**

### Common False Positives (CRITICAL)

These scenarios report success but feature is broken:

```
âŒ Click succeeded â†’ But onClick handler missing
   Test: âœ… Step passed
   Reality: âŒ Nothing happened (screenshot unchanged)

âŒ Fill succeeded â†’ But validation blocked save
   Test: âœ… Form filled
   Reality: âŒ Data not saved (check file contents)

âŒ Navigation succeeded â†’ But redirect didn't happen
   Test: âœ… Navigated to /save
   Reality: âŒ Still on /edit (check URL/screenshot)

âŒ Action completed â†’ But feature half-broken
   Test: âœ… All steps passed
   Reality: âŒ UI shows error state (check screenshot)
```

**Default assumption: If screenshot shows no change â†’ Application bug, not test issue.**

**â†’ Complete verification guide: [VERIFICATION-CHECKLIST.md](references/VERIFICATION-CHECKLIST.md)**

---

## Quick Start

1. **Initialize:** `tsty init`
2. **Create discovery flow** to capture HTML: [E2E-TESTING-GUIDE.md](references/E2E-TESTING-GUIDE.md)
3. **Extract selectors** from HTML (use exact `placeholder=`, `text=` from captured HTML)
4. **Create action** with simple selectors
5. **Test immediately:** `tsty run flow-name --fail-fast`
6. **Verify outcome:** Check screenshot shows expected change (not just exit code 0)
7. **If doesn't work:** Read code â†’ Fix bug â†’ Re-test

**â†’ Full workflow: [E2E-TESTING-GUIDE.md](references/E2E-TESTING-GUIDE.md)**

---

## ğŸ–¥ï¸ Testing Development Servers

**Dev servers have expected errors** that should NOT fail tests:

```
Expected in dev mode:
âœ“ HMR (Hot Module Reload) messages
âœ“ 404s for source maps (*.map files)
âœ“ React DevTools notifications
âœ“ Fast Refresh rebuilding logs
âœ“ Next.js compilation warnings
```

### When to Disable Console Monitoring

**Use `--no-monitor` flag for:**

1. **Local development servers** (default for tsty framework itself)
   ```bash
   tsty run my-flow --fail-fast --no-monitor
   ```

2. **Testing a framework that tests itself** (meta-testing)
   ```bash
   # When testing tsty's own dashboard
   tsty run test-dashboard-feature --no-monitor
   ```

3. **Any dev server with expected console noise**

### When to Enable Console Monitoring

**Use `monitorConsole: true` for:**

1. **Production builds in CI/CD**
   ```json
   {
     "monitorConsole": true,
     "failFast": true
   }
   ```

2. **Testing user-facing applications** (not dev infrastructure)

3. **Strict quality gates** where ANY console error should fail

### Configuration Examples

**Dev environment** (lenient):
```json
{
  "name": "Test Feature",
  "baseUrl": "http://localhost:3000",
  "monitorConsole": false,
  "failFast": true
}
```

**Production/CI** (strict):
```json
{
  "name": "Test Feature",
  "baseUrl": "https://app.example.com",
  "monitorConsole": true,
  "failFast": true
}
```

**Rule of thumb**: If testing shows 404s or HMR messages â†’ Use `--no-monitor`

---

## When to Read What

**Starting your first test:**
- [E2E-TESTING-GUIDE.md](references/E2E-TESTING-GUIDE.md) - HTML-first approach
- [USER-FIRST-TESTING.md](references/USER-FIRST-TESTING.md) - User-like interactions

**After EVERY test run:**
- [VERIFICATION-CHECKLIST.md](references/VERIFICATION-CHECKLIST.md) - Step-by-step validation

**When feature doesn't work:**
- [BUG-DETECTION-CHECKLIST.md](references/BUG-DETECTION-CHECKLIST.md) - â­ **START HERE** - Systematic bug finding
- [BUG-FIXING-WORKFLOW.md](references/BUG-FIXING-WORKFLOW.md) - Investigation & fixing

**Building complex flows:**
- [FLOW-STRUCTURE.md](references/FLOW-STRUCTURE.md) - JSON schema
- [EXAMPLES.md](references/EXAMPLES.md) - 11 real-world patterns

**Need reference:**
- [ACTIONS.md](references/ACTIONS.md) - 48 Playwright primitives
- [VARIABLES.md](references/VARIABLES.md) - Dynamic variables & Faker
- [CLI-REFERENCE.md](references/CLI-REFERENCE.md) - All commands
- [CONFIG.md](references/CONFIG.md) - Configuration options

**Troubleshooting:**
- [ANALYSIS-METHODS.md](references/ANALYSIS-METHODS.md) - Analyzing reports/screenshots
- [FAIL-FAST-GUIDE.md](references/FAIL-FAST-GUIDE.md) - Stopping on first failure

**Using dashboard:**
- [DASHBOARD.md](references/DASHBOARD.md) - Visual editors

---

## Essential CLI Commands

```bash
# Setup
tsty init                          # Create .tsty/ directory

# Running tests (ALWAYS use --fail-fast during development)
tsty run <flow> --fail-fast        # Stop on first failure (60-78% faster)
tsty run <flow> --device mobile    # Test on mobile viewport

# Listing
tsty list                          # List flows
tsty list actions                  # List user actions
tsty primitives                    # List 48 primitives
tsty primitives mouse              # List mouse primitives

# Dashboard
tsty                               # Start visual dashboard (localhost:4000)
```

**â†’ Full reference: [CLI-REFERENCE.md](references/CLI-REFERENCE.md)**

---

## Prerequisites

**âš ï¸ CRITICAL: Before anything, initialize:**

```bash
tsty init  # Creates .tsty/ directory with config, subdirectories
```

**If you see "No configuration file found"** â†’ Run `tsty init` first.

---

## Workflow Approaches

**CLI-Only (Recommended for Autonomous Testing)**
- Create flows as JSON in `.tsty/flows/`
- Run via CLI: `tsty run flow-name --fail-fast`
- Fastest iteration for autonomous fixing
- **âš ï¸ CRITICAL: ALWAYS use headless mode (`headless: true`) for autonomous/agentic testing**
  - Prevents browser windows from appearing
  - Faster execution
  - Lower resource usage
  - Essential for background/automated workflows

**Dashboard (For Interactive Editing)**
- Start: `tsty` â†’ http://localhost:4000
- Visual flow builder with drag-and-drop
- Still iterate: run â†’ fix â†’ re-run
- Can use `headless: false` for manual debugging only

**Tsty tests ANY web application** - your apps, third-party sites, local servers, etc.

---

## Core Iteration Loop

**Phase 1: Setup & Run**
```bash
tsty run my-test --fail-fast
```

**Phase 2: Analysis (CRITICAL)**

**CRITICAL FIRST QUESTION: Did the outcome make sense?**

**Outcome Verification Checklist:**
- [ ] Does the screenshot show the expected UI change?
- [ ] Is the created file/data functional (not just exists)?
- [ ] Would a real user be satisfied with this result?
- [ ] Did EVERY step achieve its intended outcome?

**If ANY checkbox is unchecked â†’ Investigate and FIX the bug**

**Then analyze ALL data sources:**
1. **Report** (`.tsty/reports/`): `success`, `error`, `consoleErrors`
2. **Screenshots** (`.tsty/screenshots/run-*/`): Visual changes
3. **Console Logs** (`steps[].console`): JS errors
4. **Assertions** (`steps[].assertions`): Failed assertions

**â†’ See [ANALYSIS-METHODS.md](references/ANALYSIS-METHODS.md) for complete guide.**

**Phase 3: Fix & Re-run (ITERATE)**

**Identify what to fix:**
- **Console errors** â†’ Fix **application code** (JS bugs in .tsx/.ts/.jsx/.js files)
- **Selector timeouts** â†’ Fix **test selectors** (wrong selector in flow/action JSON)
- **Failed assertions** â†’ Fix **test assertions** or **app behavior**
- **Visual bugs** â†’ Fix **application code** (CSS/layout in .css/.tsx files)
- **Missing elements** â†’ Fix **application code** (component rendering)

**Apply fixes:**
1. Use Read tool to examine relevant files
2. Use Edit tool to fix issues
3. Re-run: `tsty run my-test --fail-fast`
4. Repeat Phase 2 (analyze)
5. Continue until: exit 0, screenshots correct, no errors

**â†’ See [ITERATIVE-WORKFLOW.md](references/ITERATIVE-WORKFLOW.md) for detailed patterns.**

---

## Decision Tree: STOP or CONTINUE?

**After EVERY test run:**

```
Exit code 0?
â”œâ”€ YES â†’ View screenshots â†’ Issues? â†’ Note as UX improvements â†’ DONE
â””â”€ NO â†’ consoleErrors > 0?
   â”œâ”€ YES â†’ ğŸš¨ FIX APP CODE (JS bug) â†’ Re-run
   â””â”€ NO â†’ Selector timeout?
      â”œâ”€ YES â†’ Check screenshot â†’ Fix selector or app â†’ Re-run
      â””â”€ NO â†’ Read error â†’ Fix â†’ Re-run
```

**Key principles:**
- **Console errors** = Fix **app code** (JavaScript bugs)
- **Selector errors** = Fix **test selectors** (wrong selector)
- **Exit 0 + screenshots OK** = DONE (create next test)

**â†’ See [QUICK-DECISIONS.md](references/QUICK-DECISIONS.md) for complete decision trees.**

---

## Flow Structure

**Minimal example:**

```json
{
  "name": "Test",
  "baseUrl": "http://localhost:3000",
  "failFast": true,
  "steps": [{
    "name": "Homepage",
    "url": "/",
    "capture": { "screenshot": true },
    "primitives": [{ "type": "click", "selector": "button" }]
  }]
}
```

**Key fields:** `url` (navigate), `primitives` (actions), `expectedUrl` (verify), `capture` (screenshots/HTML)

**â†’ See [FLOW-STRUCTURE.md](references/FLOW-STRUCTURE.md) for complete schema.**

---

## 48 Playwright Primitives

**Primitives** are framework-provided building blocks (auto-generated from Playwright).
**Actions** are user-created behaviors (composed from primitives).

**48 primitives across 7 categories**: Navigation (5), Mouse (5), Input (8), Waiting (6), Locators (7), Info (4), Other (13)

```bash
tsty primitives           # List all 48 primitives
tsty primitives mouse     # List by category
```

**â†’ See [ACTIONS.md](references/ACTIONS.md) for complete primitive reference and examples.**

---

## Variable Interpolation

**Syntax:** `${variable}`

**Built-in:** `${timestamp}`, `${datetime}`, `${baseUrl}`, `${credentials.email}`

**Faker.js (300+):**
```
${faker.person.fullName}
${faker.internet.email}
${faker.location.city}
${faker.company.name}
${faker.lorem.sentence}
```

**â†’ See [VARIABLES.md](references/VARIABLES.md) for complete reference.**

---

## Configuration

`.tsty/config.json`:

```json
{
  "baseUrl": "http://localhost:3000",
  "credentials": { "email": "test@example.com", "password": "pass" },
  "playwright": { "headless": true, "timeout": 30000 }
}
```

**âš ï¸ CRITICAL for Autonomous/Agentic Testing:**
- **ALWAYS set `"headless": true`** (default, but verify!)
- Only use `"headless": false` for manual debugging with visible browser
- Headless mode prevents browser windows during autonomous iteration

**â†’ See [CONFIG.md](references/CONFIG.md) for complete guide.**

---

## Troubleshooting

**Common issues:**
- "No configuration file" â†’ Run `tsty init`
- Port conflict â†’ `tsty --port 3001`
- Flow not found â†’ Check `tsty list` or `ls .tsty/flows/`
- Playwright not installed â†’ `npx playwright install chromium`
- Timeout errors â†’ Check selectors and page load state

**Note:** Playwright launches isolated browser instances. Dev server must be running before tests.

**â†’ See [TROUBLESHOOTING.md](references/TROUBLESHOOTING.md) for complete guide.**

---

## Reference Documentation

**Load as needed for detailed information.**

### ğŸ¯ Core Workflows (Read First)

- **[ITERATIVE-WORKFLOW.md](references/ITERATIVE-WORKFLOW.md)** - â­ CRITICAL: Iteration loop with examples
- **[E2E-TESTING-GUIDE.md](references/E2E-TESTING-GUIDE.md)** - â­ CRITICAL: HTML-first approach
- **[VERIFICATION-CHECKLIST.md](references/VERIFICATION-CHECKLIST.md)** - â­ CRITICAL: Step-by-step validation
- **[ANALYSIS-METHODS.md](references/ANALYSIS-METHODS.md)** - Analyzing reports/screenshots/logs
- **[USER-FIRST-TESTING.md](references/USER-FIRST-TESTING.md)** - â­ User-like interactions & common mistakes
- **[BUG-FIXING-WORKFLOW.md](references/BUG-FIXING-WORKFLOW.md)** - â­ Investigation & bug fixing

### ğŸ“š Technical References

- **[FLOW-STRUCTURE.md](references/FLOW-STRUCTURE.md)** - Flow JSON schema with examples
- **[ACTIONS.md](references/ACTIONS.md)** - 48 Playwright primitives
- **[VARIABLES.md](references/VARIABLES.md)** - Variable interpolation & Faker.js
- **[CONFIG.md](references/CONFIG.md)** - Configuration options
- **[CLI-REFERENCE.md](references/CLI-REFERENCE.md)** - All CLI commands

### ğŸ¨ Features & Guides

- **[DASHBOARD.md](references/DASHBOARD.md)** - Dashboard features
- **[FAIL-FAST-GUIDE.md](references/FAIL-FAST-GUIDE.md)** - Fail-fast mode details
- **[EXAMPLES.md](references/EXAMPLES.md)** - 11 real-world examples

### ğŸ“ Standards & Analysis

- **[VISUAL-ANALYSIS-GUIDE.md](references/VISUAL-ANALYSIS-GUIDE.md)** - Visual analysis methodology
- **[ANALYSIS-CHECKLIST.md](references/ANALYSIS-CHECKLIST.md)** - Quick checklist
- **[accessibility-standards.md](references/accessibility-standards.md)** - WCAG AA standards
- **[ux-production-analysis.md](references/ux-production-analysis.md)** - UX patterns
- **[framework-fixes.md](references/framework-fixes.md)** - Framework-specific fixes
- **[common-ux-issues.md](references/common-ux-issues.md)** - Common anti-patterns
- **[layout-patterns.md](references/layout-patterns.md)** - Layout best practices

### ğŸ› ï¸ For Maintainers

- **[DESIGN-PHILOSOPHY.md](references/DESIGN-PHILOSOPHY.md)** - Design principles & extension guidelines

---

## When to Use This Skill

**Auto-trigger (proactive):**
- User implements UI features â†’ Test with Tsty
- User updates pages â†’ Verify no regressions
- User makes layout changes â†’ Check visual correctness

**Explicit requests:**
- "Test the dashboard visually"
- "Check accessibility"
- "Run E2E tests"
- "Find layout issues"

**Proactive suggestions:**
- User: "Added modal" â†’ You: "Let me test it"
- User: "Updated layout" â†’ You: "I'll run regression tests"

---

## Key Principles

### Technical
- **Directory**: `.tsty/`
- **Commands**: `tsty` or `npx qa` (never run scripts directly)
- **Primitives**: 48 auto-generated from Playwright's Page API
- **Actions**: User-created behaviors composed from primitives
- **Variables**: Faker.js for dynamic data (300+)
- **Screenshots**: `run-{flowId}-{timestamp}/` per run

### Workflow
- **ITERATE**: Run â†’ Analyze â†’ Fix â†’ Re-run (don't stop after one run)
- **ANALYZE ALL**: Reports + screenshots + logs + assertions
- **FIX AUTONOMOUSLY**: Apply fixes immediately
- **VERIFY FIXES**: Always re-run after fixes

### Analysis
- **Visible only**: Analyze what's in screenshots/logs
- **Priority**: Errors â†’ Critical bugs â†’ Assertions â†’ Visual â†’ UX
- **Two-tier**: Critical issues + UX improvements
- **Concise**: 1-2 lines per issue

---

## Framework Info

- **Package**: `@vipro/tsty`
- **GitHub**: https://github.com/mde-pach/tsty
- **Playwright**: https://playwright.dev
- **Faker.js**: https://fakerjs.dev/api/
